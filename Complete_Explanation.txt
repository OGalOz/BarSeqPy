    TODO:
        
        Finish writing table outputs from FEBA_Save_Tables 
            (now on 'Gene Counts')

        Compare outputs from AvgStrainFitness between Python and R.

        Write explanation of Pearson vs Spearman in different settings:
            Pearson is linear correlation
            Spearman checks monotonic correlations
            Spearman done for Crude Operon and Adjacent pair correlations
            Pearson done for all other correlations?

        Run . testPy.sh 4

        How do you explain the whole 'strain Pseudo Count' and strainFit Weight
               etc from analysis1 ?? 

        Why are lr and lrn exactly the same? (from BP4?)
        Why do they start so low down the number of genes?

        Get examples of intermediate variables in AvgStrainFitness, StrainPseudoCount, etc.
        strain_lr is not completely empty
        'normalize_per_strain_values' doesn't make sense (analysis2)
        strain_lrn is not returning any results
            Where is strain_lrn being computed?
                At function create_strain_lrn in analysis2

        specphe (specific phenotypes) and cofit not being computed (analysis3)
        No description for NormalizeByScaffold in analysis1

        Ask meaning of function:
        getStrainPseudoCount
    
    Vocabulary:
        exp_name: Experiment name, string, like 'set2IT008' the name of a specific experiment.
        SetName: Like 'set2', a more general collection of experiments, within which indexes 
                 define experiments.
        Date: The day on which an experiment may have occured
        Strain: associated with a row in all.poolcount, this refers to a unique mutation
                in the DNA of an organism, in that it had a transposon insertion.
                Each barcode and location is essentially a 'strain', and the number
                of times that strain appears is correlated with the number of
                reads found.

    Function Descriptions:
        Use 'Rapid Quantification of Mutant Fitness in 
        Diverse Bacteria by Sequencing Randomly Bar-Coded 
        Transposons' pages 12-14 as a reference
        create_strain_lrn (analysis2): 
            We take the strain log ratios, which are created in the function 
            'StrainFitness' from analysis1 and we normalize them by finding
            the median over all the values from the same scaffolds and
            subtracting that from the log ratios.
            We also take a dataframe that is the gene log ratios - gene
            normalized log ratios, and if those exist at a read, then
            we subtract those instead of the median.

        analysis1:
            In this part of the analysis, we compute fitness per strain as well as
            fitness per Gene. The way we do this is that we go through each experiment,
            which are all the columns in all_df (all.poolcount dataframe) after the
            metadata columns.
            The first thing we do is we get a list of all the experiment names, and
            we place these in a list called 'all_index_names'. We also get the subset
            of all the strains that are useful for Gene Fitness computations, the
            number of strains in this subset is the number of 'True's in the list
            'strainsUsed', so we compute this number and name it 
            'nAllStrainsCentralGoodGenes'. After that we get the subsets of the 
            dataframes all_df and t0tot (the Time0 totals summed over all_df) to
            be used in Gene Fitness computations later.
            Next, if one wanted to run the computations on a subset of the experiments, 
            they could give nDebug_cols=N where N is the number of experiments
            they would like to run analysis on.
            Finally, before running the analysis on each selected experiment,
            we find the subset of the good strains which were inserted in 
            the first half of the genes (in other words if the insertion occured
            before the halfway point of the gene). We call this array of booleans
            use1.
            Now we run the analysis (gene_strain_fit_func) on each experiment 
            (number of experiments we run on = nDebug_cols)
            and each analysis returns a dictionary with 3 values: gene_fit (a pd dataframe
            with gene fitness values), strain_fit (a pd series with strain fitness values),
            and strain_se (a pd series with strain standard error values). Note that the
            number of rows in the dataframe 'gene_fit' is equivalent to the total number
            of usable genes, whereas the two pd series are the same length, and are equivalent
            to the total number of strains in all.poolcount (much longer than the total
            number of usable genes) (pd stands for pandas, a python library).
            In a larger dictionary called, GeneAndStrainFitResults,
            we create a key with the current experiment, and the value is the dictionary
            mentioned above. In other words, we get a dictionary with keys 
            ['gene_fit', 'strain_fit', 'strain_se']
            within a dictionary called GeneAndStrainFit with keys being the experiment
            names, and each experiment is associated with one of the smaller dictionaries.
            We return this dictionary GeneAndStrainFitResults.
        gene_strain_fit_func (analysis1):
            This function is run for every single set_index_name in all_df, and that set_index_name
            is passed into this function as the first argument, 'set_index_name'. All other arguments
            are not changed at all when this function is called and are documented elsewhere. 
            We get results for GeneFitness (fitness per Gene), and Strain Fitness (fitness
            per strain). GeneFitness gives a dataframe whose number of rows is the number of genes
            in genesUsed. StrainFitness returns two series whose length is the same as the total
            number of strains in all.poolcount. StrainFitness is a very simple function that gives
            log2 ratios and standard error, each of which take only a line to compute. On the other
            hand, GeneFitness is a very complicated function in which multiple normalizations and
            statistical computations are done in order to make the GeneFitness a more reasonable
            value.
            Within this function, we first find the associated t0set name related to our current 
            experiment, and get the reads and t0 read sums. If our current experiment
            (denoted by the set_index_name) is a Time0 experiment, then we subtract the current
            experiment values from the sum for this Time0, since the sum for this Time0 is
            an aggregation over the several experiments associated with this Time0.
            If this is the only Time0 experiment associated with this Time0, then we
            skip computation for it. At this point, we get the total StrainFitness
            values, which, as mentioned above, returns two series whose length is the 
            same as the total number of strains in all.poolcount. These two series are
            StrainFitness and Standard Error per strain. We don't use these two series
            further within this function, now we move on to computing per Gene Fitness.
            When computing Gene Fitness, we use a subset of all.poolcount in which 
            the strains were inserted into genes and in good locations and in abundant 
            enough amounts over genes and over scaffolds. GeneFitness is a very complex 
            function which is described in its own Description section, it returns
            a dataframe which per Gene values.

        GeneFitness (analysis1):
            This runs on every experiment (set + Index name).
            Our four primary inputs are the exps_used_strains (current experiment
            strains which are used), all_used_locId (the locusIds for all the used
            strains), all_used_f (the insertion fraction for all the strains),
            and the t0_used, which is the related t0 sums for the current experiment.
            First, we call Average Strain Fitness on all the strains given as an input;
            this gives us a dataframe (main_df) with values per Gene. The number of rows
            in this dataframe are the total number of usable genes, the ids of the genes
            are called 'locusId'.
            The column names in this dataframe are
                locusId <str>: The locusId to which this row is associated.
                fit: fitRaw column normalized by Median 
                fitNaive (float): Median normalized log2 difference between tot0 and tot 
                fitRaw (float): Sum of weighted adjusted fitness scores divided by total weight. 
                sd (float): Standard Deviation computed fancy way
                sumsq (float): [Sum of the weighted square of the difference between adjusted fitness 
                                and fitRaw] divided by total weight.
                sdNaive (float): Standard Deviation computed in Naive way 
                n (int): Total number of strains in this locusId
                nEff (float ): The sum of the strain weights in these indeces/ max weight
                tot (int ): The sum of the experiment reads over the locusID
                tot0 (int): The sum of the Time0s over the locusId
            Then we normalize the 'fit' values using the function NormalizeByScaffold,
            which simply adds a column to our dataframe, the column is called
            'fitnorm', for 'Normalized Fitness'.
            Then we call Average Strain Fitness twice again. Once for the whole set of 
            gene insertions, once for the insertions within .1<f<.5, and once for .5<f<.9. 
            The num rows of first_half_df and second_half_df (called for .1<f<.5 and .5<f<.9) is nGenesUsed12, 
            which is the total number of genes that have enough insertions on both sides of the gene.
            We use these two dataframes (first_half_df and second_half_df) to get statistical information
            on how balanced the insertions are regarding gene Fitness (pseudovar, se, t).
            The new dataframe columns we compute are 
            fit1, fit2, fitnorm1, fitnorm2, tot1, tot0_1, tot2, tot0_2, pseudovar, se, t
            fit1 through tot0_2 are just the computed fitness scores for the 1st and 
            second halves respectively, except for fitnorm1 and fitnorm2 are computed
            like this:
                fit1 + fitnorm - fit
            Where fitnorm and fit come from the main_df dataframe, and fit1 are the fit
            scores for first_half_df. fitnorm2 is computed similarly just with fit2 instead of
            fit1.
            When it comes to the reasoning behind computing 'pseudovar', 'se' and 't', 
            things get complicated. Explained separately. 

        AvgStrainFitness (analysis1): Done for each experiment_name
            We take three main input variables:
                1. exp_used_strains: The used reads values from all_df, 
                    it is a pandas Series of values, whose index is the row number
                    from all.poolcount where it originated, and whose length is
                    nAllStrainsCentralGoodGenes*, and the * is there because
                    it could include strains that are in all the genes
                    with good insertions, or it could only be the reads
                    with even stronger gene insertions, where there are
                    enough reads in both the top and bottom half.
                2. t0_used: The sum of the t0 reads for this experiment,
                    taken from all_df, and summed over the columns whose
                    experiments are associated with the t0 value for
                    this experiment_name. This is also a pandas Series,
                    whose  indexes are exactly the same as for exp_used_strains.
                    length = nAllStrainsCentralGoodGenes*
                3. all_used_locId: The associated locusIds for the above
                    two pandas Series, has the same index. Also taken
                    from all.poolcount (all_df)
                    length = nAllStrainsCentralGoodGenes*
            This function is run 3 times. The first time we run it on
            all the strains who are inserted in a good place in genes
            that we are using with high enough abundance. (called main_df)
            The second time we run it we are running it on the strains who are 
            inserted within 0.1 and 0.5 of the gene (0.1<f<0.5). (called first_half_df)
            The third time we run it we are running it on the strains who are 
            inserted within 0.5 and 0.9 of the gene (0.5<f<0.9). (called second_half_df)
            The next step is that we get the 'readratio', which is a float.
            The readratio is the sum of the reads for this experiment
            divided by the sum of the reads for the time0s for this
            experiment.
            Now we create a variable called 'strainFit', which is essentially
            taking the log2 values of exp_used_strains (the experiment original
            reads) and subtracting the log2 values of the time0s for those reads,
            and then doing a median normalization of the difference.
            So log2(originalreads) - log2(t0reads) = x; then return mednorm(x).
            BUT we add in the readratio to the original reads and the inverse
            of the readratio to the t0reads. Why?
            Now we create strainPseudoCount. In order to create strainPseudo count,
            first we get the medians of the strainFit values (already log2 normalized) 
            over the various genes. So suppose there are 15 strains (log2 normalized)
            in one gene (e.g. 'trp'); then we take the median of all those and essentially
            create a mapping from locusId -> median. This is called geneFitMedians.
            Then we also get a counting of how many times each gene was inserted into,
            so for that gene 'trp' we would get a mapping to the number 15. This 
            is done for all genes (represented by locusId strings) and is placed
            in a variable called locusId2TimesSeen_d.
            Now we create the strainPseudoCount list, whose length will be 
            nAllStrainsCentralGoodGenes(*), i.o.w as long as the three main
            inputs. How we create it is like this:
            We go through each locusId in locusId2TimesSeen_d, and check if the number
            of times it was seen is greater than a threshold integer called
            'minGeneFactorNStrains'. If it is greater than this threshold, we
            add the number 2^(median of the locusId (from geneFitMedians)) multiplied
            by the readratio, which is sum(reads)/sum(time0s). Which is essentially
            reversing the strainFit action, making strainPseudoCounts essentially
            the strain counts but over the medians.
            That being said, if the number of times the locusId was seen doesn't 
            pass the threshold, then we simply add the readratio itself to the
            strainPseudoCount list.
            Now we use the strainPseudoCount list to adjust the strainFit values.
            This part is unclear to me why it's done the way it is done.
            In order to create an adjusted StrainFit, we take the strainPseudoCount
            list, and take its square root (element-wise) and call it expPC,
            then we create a T0 pseudocount which is 1/expPC (call it t0PC). 
            Now we adjust the strainFit by adding these PseudoCount square root
            and inverse to their respective original reads values, taking 
            the log2 of those and subtracting the T0 sum from the Exp sum,
            and also subtracting a 'strainFitAdjust' number. For this
            strainFit, which is adjusted, we don't apply median normalization.
            Now we compute the Standard Deviation per strain.
            Then we get weights per strain, based on the number of reads in the Time0
            and the experiments. The weights are used to measure strainFitness for
            a gene more accurately. The strains with less reads are weighted less,
            and the strains with more reads are weighted higher.
            Once we have the Standard Deviation per strain, the weights per strain,
            and the adjusted strain fitness, then we can go on to compute the following
            values per gene:
                fitRaw (float): Sum of weighted adjusted fitness scores divided by total weight. 
                sd (float): Standard Deviation computed fancy way
                sumsq (float): [Sum of the weighted square of the difference between adjusted fitness 
                                and fitRaw] divided by total weight.
                sdNaive (float): Standard Deviation computed in Naive way 
                n (int): Total number of strains in this gene
                nEff (float ): The sum of the strain weights in these indeces/ max weight
                tot (int ): The sum of the experiment reads over the locusID
                tot0 (int): The sum of the Time0s over the gene
            We create a dictionary which stores all of these values per gene, and then
            once we're done computing over all the locusIds, we convert the dictionary
            into a dataframe, with the columns being the above values (fitRaw,...,tot0).
            Then we create two new values which are based on the above values over all
            the genes: 'fit' and 'fitNaive'. 'fit' is the median normalization of 'fitRaw' from
            each gene, then 'fitNaive' is a naive computation of fitness based on tot and
            tot0 (median normalized log2 difference of the two).
            We return this dataframe called 'fitness_df'. The total number of rows in
            this dataframe is the number of used Genes, since it's one row per used
            gene.
       NormalizeByScaffold (analysis1):
          We create the column 'fitnorm' for main_df from GeneFitness.
          How:
          We take the series of locusIds from main_df (which are unique),
          and find their locations within the series genes_df['locusId'] which are also
          unique. Then we take the subset of the dataframe genes_df which match
          to those locations and take its scaffoldId, begin values and locusIds and
          combine them with the fitness values from AvgStrainFitness, and create
          a dataframe called tmp_df.
          Then we group values by scaffoldIds (which are not unique), and get
          the rows of tmp_df which are associated with that scaffoldId.
          We check that the total number of rows associated with that scaffoldId
          pass the threshold 'minToUse'. If it doesn't, we remove the fitness
          values for those rows. If it does we continue to the next part.
          Now we take the median of the rows associated with that scaffoldId
          and subtract it from them (median normalization on a subset of the
          rows).
          Then, if the number of rows associated with this scaffoldId pass
          the window threshold, we take the running median with window size
          251 of the sorted genes (A running median looks backwards and 
          forwards the same amount and computes the median using half 
          the window after and half before, so in this case 125 after and 
          125 before), and then we subtract that median from those values.
          Then we also normalize by the mode, and a simple way to 
          estimate the mode if there aren't repeating values is through
          the gaussian kernel density estimation function:
          //rmflight.github.io/post/finding-modes-using-kernel-density-estimates/

            
            



                    

            Within this function we create the following variables:
                strainWeight, strainFit_adjusted, strainSD.

                    strainWeight: comes from t0_used, and exp_used_strains
                    strainFit_adjusted: comes from t0_used, exp_used_strains,
                                        condPseudoCount, and t0PseudoCount.
                                        condPseudoCount and t0PseudoCount
                                        come from strainPseudoCount,
                                        which comes from geneFit1 and readratio,
                                        geneFit1 comes from strainFit,
                                        which is the simple computation
                                        you'd expect the program to do.
                                        



    Main Variables:
        strainsUsed:
            list<bool> Length of all_df which decides which of the 'strains'
            we actually use. Must pass two qualifications:
            The mean of the t0tot over the strain has to pass a threshold 
                'minT0Strain'
            The insertion location of the strain has to be between 0.1 and 0.9
            of a gene.

        What are main lengths and how do they relate to lengths of input variables?
        Main lengths:
            nAllStrains = number of rows ( all.poolcount )
            nAllStrainsCentral = number of rows in all.poolcount with 0.1<f<0.9
            nAllStrainsCentralGoodGenes = number of rows in all.poolcount with 0.1<f<0.9
                                          AND all locusIds are in the list 'GenesUsed'
                                            (27659 in Keio) - also known as nUsefulReads
            nAllStrainsCentralGoodGenes12 = number of rows in all.poolcount with 0.1<f<0.9
                                          AND all locusIds are in the list 'GenesUsed12'
                                            (27659 in Keio) - also known as nUsefulReads
            nAllStrainsCentralGoodGenes* = either of nAllStrainsCentralGoodGenes(12) 
            nTotalGenes = number of rows (genes.GC)
            nGenesUsed = (len(genesUsed)) number of rows in genes.GC that we actually use
                        which is equivalent to the number of unique genes
                        that have good insertions in them. (1355 in Keio)
                        Which is the same as the output fitness and t score dataframes
            nGenesUsed12 = (len(genesUsed12)) number of locusIds with a good amount of 
                            insertions in both halves of 'f' from all_df. Both df1 and df2 
                            in GeneFitness() have this number of rows.
            nGenesUsed* = either nGenesUsed or nGenesUsed12
            nExperiments = number of rows in experiments file
    

    Questions:
        Why are we normalizing by scaffold?
        There are issues with some outputs: fit_log_ratios_unnormalized_naive:
            The dataframe isn't combined, it's just two dataframes stacked on top of 
            one another.
        Should we allow people to get the raw results from their reads, the raw log2
        differences between values and time0s? Instead of all the normalization


    Outputs:

    The Standard output columns are:
            locusId, sysName, desc experiment_1, experiment_2, ..., experiment_n
            where experiment_1 etc refer to the setName + Index values
            These often have the same number of rows and contain numerical values under 
            the various experiments.

    Throughout the following, these column data types are fixed:
        locusId (str): The gene ID, also known as 'locus ID'
        desc (str): Short description of what a gene does
        name (str): Name of the experiment, or name of a gene 
        strand (str): Either '+' or '-', indicating positive or minus strand, respectively.
        begin (int): Where the object of interest begins within a scaffold
        end (int): Where the object of interest ends within a scaffold
        sysName (str): Another identifier for a gene


        fit_logratios_unnormalized_naive: The fitness logratios that are unnormalized
                                        Have Standard output columns
        cofit: Contains columns:
            locusId, sysName, desc, hitId, cofit, rank, hitSysName, hitDesc

        fit_logratios:
                                        Have Standard output columns

        fit_quality:
            Has the following columns:
                name, short, t0set, num, nMapped, nPastEnd, nGenic, nUsed, gMed, gMedt0, 
                gMean, cor12, mad12, mad12c, mad12c_t0, opcor, adjcor, gccor, maxFit, u

        fit_standard_error_naive:
                                        Have Standard output columns

        fit_standard_error_obs:
                                        Have Standard output columns

        fit_genes: (Complete) The genes.GC file with an extra column called 'used' which
                        contains boolean values for whether or not the gene was used.
                        Contains the following columns:
                            locusId (str):
                            sysName (str):	
                            type (int): Identifier for the type of gene
                            scaffoldId (str):	
                            begin (int):	
                            end (int):	
                            strand (str): '+'|'-'	
                            name (str): typical name for gene, e.g. "thrL"	
                            desc (str): What does the gene do?
                            GC (float):	Fraction of nucleotides that is GC
                            nTA (int):	number of TAs?
                            used (bool): gene used in analysis?

        fit_t:
                                        Have Standard output columns

        gene_counts:
                                        Have Standard output columns

                    Counts the number of times insertions occured in that gene in a given experiment.

        high_fitness: 
            Hybrid of a few of the other tables: Columns:
            locusId, expName, fit, t, se, sdNaive, name, Group, Condition_1, 
            Concentration_1, Units_1, Media, short, u, maxFit, gMean, sysName, desc

        specific_phenotypes:
            locusId, sysName, desc, short, Group, Condition_1, Concentraion_1, Units_1, Condition_2, Concentration_2, Units_2

        strain_fit:
            barcode, rcbarcode, scaffold, strand, pos, locusId, f, used, enoughT0, experiment_1   experiment_2  ... experiment_n
            
        strong:
            locusId, name, t, lrn, sysName, desc, short
        expsUsed:
           All the column names from the input experiments file + the following four:
                num (int) (counts which experiment, 
                short (str): either 'Time0' or a brief description of experiment conditions,
                name (str): the experiment name, e.g. set2IT003 
                t0set (str): A date which refers to the time0 to which we compare this one 
        

    
    Breakpoint Outputs Explained:
        BP3:
            gene_fit:
                Number of rows = length of genesUsed as input to analysis1

        GeneFitResults:
            For each experiment name, there are 3 different important variables:
               gene_fit, strain_fit, strain_se
            
            The length of gene_fit is nGenesUsed
            The length of strain_fit is  nAllStrainsCentralGoodGenes (nUsefulReads)





    Program is divided into 7 phases:
        1. Data Preparation 1: Naming and formatting (labeling)
        2. Data Preparation 2: Accounting for Controls (Known as "Time0")
                a) Finding and Summing Controls
                b) Finding which strains and genes are good to use and pass thresholds.
        3. Computations 1: Log Ratios, T-scores and Normalizations
        4. Computations 2: Correlations and meta-statistics
        5. Computations 3: Cofitness and finding high fitness values
        6. Exporting and Visualizing Graphs
        7. Website building


    Requirements:
        Inputs:
            all.poolcount: List of 'strains'. If a transposon was inserted inside a gene,
                then the field locusId will no longer be empty, and the field 'f' will no
                longer be empty, since 'f' measures the fraction of the gene in which
                the transposon was inserted, i.e. if it was inserted in the 25th% of
                the gene in terms of length, then its 'f' would be 0.25.
                For each identifier for an experiment, we count the number of times
                that strain appears.


        
       All the locusIds in all.poolcount have to exist in the genes file (genes.GC)

       Experiments File:
        If you want to drop an experiment (row in experiments file), you must create a column
         called 'Drop' and write in "true" (upper or lower cases don't matter). You can leave
         this column in the other experiments as nothing. You can also remove the row representing
         the experiment from the file entirely.
        The 'SetName' column contains the setname (lane) the experiments come from, 
        where as the 'Index' is more specifically the exact solution. 
        So the 'SetName' + 'Index' indicates a unique collection.

        Don't allow users to add 'strainsUsed'
        

    Random:

        Individual Experiments are denoted both by a row in the 'Experiments' file, and by a SetName.Index;
        Either one can be thought of as an individual experiment. Eventually, the "." in the SetName.Index is
        removed, and we are left with just SetNameIndex.
        SetNames can also be thought of as "lanes".
        How should dates be labelled? always X1/X2/X3..? 
        On any given date, a few experiments are Time0 experiments. So for example on  
            "6/19/2014" there were a few experiments started out of "Keio_ML9_set2", and we 
            can store all of those experiments in a dict.

        t0tot takes dates and sums all columns of all_df (that are experiments) over those dates.
        t0gN takes it one step further, and sums over the rows that have the same locusIds and that
            have central insertions.
        


    Input function is through RunFEBA.py:


        The 'readratio' is the ratio between the sum of all final values for a setIndex Name
            from all.poolcount and the sum of the corresponding t0 values.
            It is used in calculating the Strain Fitness.

        The experiments file has to follow very specific requirements:
            If you want to Drop an experiment, you need to create a column
            for all your experiments called "Drop", and within that column
            you must add the value "TRUE" (or "True").
            The column 'name' must eventually be equivalent to the indexes
                in all.poolcount
            The column 'Group' must show if it's Time0 by saying 'Time0' when it
                is indeed a time0 element

        You can also add a list of set-index names to ignore



    ScaffoldId vs Scaffold as column name?
   
    The total number of rows in the dataframes is equivalent to the numbers of
        unique locusIds in strainLocus[strainsUsed].


    gene_fit_d:

    g -> genes
    lr -> log ratios
    lrn -> log ratios normalized
    lrn1 -> log ratios normalized 1st half
    q -> quality
    u -> used
    se -> standard error
    tmp -> temporary


        Stores combined data over all set_index_names.
            *All series/dataframes ave the exact same number of rows.
        g: A list of locusIds
        lr: Some rows are completely empty (?), whenever one col has values, 
            the other also has values.
        lr1/ lr2: If two columns, if one has value, the other has the opposite value 

        At the end of the program, gene_fit_d should have keys:
            'g', 'lrRaw', 'sd', 'sumsq', 'sdNaive', 'n', 'nEff', 'tot', 'tot0', 'lr', 
            'lrNaive', 'lrn', 'lr1', 'lr2', 'lrn1', 'lrn2', 'tot1', 'tot1_0', 'tot2', 
            'tot2_0', 'pseudovar', 'se', 't', 'version', 'q', 'genesUsed', 'strainsUsed', 
            'genesUsed12', 'gN', 't0_gN', 'strains', 'strain_lr', 'strain_se', 'high' 
    
    fitQuality:
        This returns a matrix with individual stats per setindexname. So if there are 4 set index names,
        e.g. set2IT001, set2IT002, set2IT003, set2IT004; You would get a matrix with the columns:
            nUsed, gMed, gMedt0, gMean, cor12, mad12, mad12c, mad12c_t0, opcor, adjcor, gccor, maxFit
        and the rows of the 4 set index names.

    Revisions:
        all_gN isn't used but created early on and stored as a variable (Why?)
        experiments DataFrame is updated at random times, e.g. in FEBA_Fit it is 
                updated to have 'short' set to Time0 if group is Time0, which could
                have been done earlier in the program, e.g. in 'RunFEBA'. Also,
                the t0set is created at a random point.
